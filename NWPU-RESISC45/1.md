## 1
1. KL散度： D(p || q) = ∑x p(x) log(p(x)/q(x))
2. 交叉熵：H(p, q) = -∑x p(x) log(q(x))
3. D(p || q) = H(p, q) - H(p)

## 2
对于两个数组x:len(x)=n，y:len(y)=m
D(1,1) = d(x1,y1)
for j = 2 to m:
    D(1,j) = d(x1,yj) + D(1,j-1)
for i = 2 to n:
    D(i,1) = d(xn,y1) + D(n-1,1) 
    for j = 2 to m:
        D(i,j) = d(xi,yj) + min{D(i-1,j-1),D(i,j-1),D(i-1,j)}

只执行了n*m次计算 比起简单递归效率更高

## 3
maxpooling用于降采样 有助于减少过拟合并加速训练

ReLU是一种激活函数相当于max(0,x) 这会让增加网络非线性能力 